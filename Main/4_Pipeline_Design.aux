\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{yolov3}
\citation{yolov3}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Pipeline Design}{28}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:pipeline_design}{{4}{28}{Pipeline Design}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Pipeline Architecture}{28}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.3}{\ignorespaces A trivial pipeline for single person}}{28}{figure.4.3}}
\newlabel{fig:single_pipe}{{\relax 4.3}{28}{A trivial pipeline for single person}{figure.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.1}{\ignorespaces Pipeline Modules and Messages}}{29}{figure.4.1}}
\newlabel{fig:pipe_module}{{\relax 4.1}{29}{Pipeline Modules and Messages}{figure.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.2}{\ignorespaces Pipeline ROS Nodes and Message Topics}}{29}{figure.4.2}}
\newlabel{fig:pipe_msg}{{\relax 4.2}{29}{Pipeline ROS Nodes and Message Topics}{figure.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Module Functionality}{29}{section.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Message Repository}{29}{subsection.4.2.1}}
\newlabel{pipeline:MR}{{4.2.1}{29}{Message Repository}{subsection.4.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.4}{\ignorespaces \textbf  {A detection demo scenario.} We utilize YOLO3 \cite  {yolov3} as our detector and filter out all the detected persons with a confidence of less than 80\%}}{30}{figure.4.4}}
\newlabel{fig:det_demo}{{\relax 4.4}{30}{\textbf {A detection demo scenario.} We utilize YOLO3 \cite {yolov3} as our detector and filter out all the detected persons with a confidence of less than 80\%}{figure.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.5}{\ignorespaces \textbf  {A tracking demo scenario.} Taking the detection list as input, our tracker will track each person appeared in the scene and assign each of them an unique person ID.}}{30}{figure.4.5}}
\newlabel{fig:track_demo}{{\relax 4.5}{30}{\textbf {A tracking demo scenario.} Taking the detection list as input, our tracker will track each person appeared in the scene and assign each of them an unique person ID}{figure.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.6}{\ignorespaces \textbf  {An action demo scenario.} Our pose estimator will extract pose data for each person based on the cropped image, and then \textit  {data\_manager} generates pose tensor and at last, action classifier will do the action prediction (in the example, walking or standing), taking the pose tensor as input.}}{31}{figure.4.6}}
\newlabel{fig:action_demo}{{\relax 4.6}{31}{\textbf {An action demo scenario.} Our pose estimator will extract pose data for each person based on the cropped image, and then \textit {data\_manager} generates pose tensor and at last, action classifier will do the action prediction (in the example, walking or standing), taking the pose tensor as input}{figure.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Source Provider}{32}{subsection.4.2.2}}
\newlabel{pipeline:SP}{{4.2.2}{32}{Source Provider}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.1}Cv\_camera Package}{32}{subsubsection.4.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.7}{\ignorespaces ROS Topics and Messages in \texttt  {cv\_camera} node}}{32}{figure.4.7}}
\newlabel{fig:cv_camera_topics}{{\relax 4.7}{32}{ROS Topics and Messages in \texttt {cv\_camera} node}{figure.4.7}{}}
\citation{DBLP:journals/corr/RedmonDGF15}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2.2}Image\_reader Package}{33}{subsubsection.4.2.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.8}{\ignorespaces ROS Topics and Messages in \texttt  {image\_reader} node}}{33}{figure.4.8}}
\newlabel{fig:image_reader_topics}{{\relax 4.8}{33}{ROS Topics and Messages in \texttt {image\_reader} node}{figure.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Person Detector}{33}{subsection.4.2.3}}
\newlabel{pipeline:PD}{{4.2.3}{33}{Person Detector}{subsection.4.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3.1}YOLO Darknet}{33}{subsubsection.4.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.9}{\ignorespaces A YOLO detection example.}}{33}{figure.4.9}}
\newlabel{fig:yolo_demo}{{\relax 4.9}{33}{A YOLO detection example}{figure.4.9}{}}
\citation{DBLP:journals/corr/RedmonDGF15}
\citation{DBLP:journals/corr/RedmonDGF15}
\citation{roscvbridge}
\citation{roscvbridge}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.10}{\ignorespaces YOLOv3 runs significantly faster than other detection methods with comparable performance. Times from either an M40 or Titan X, they are basically the same GPU. \cite  {DBLP:journals/corr/RedmonDGF15}}}{34}{figure.4.10}}
\newlabel{fig:yolo_benchmark}{{\relax 4.10}{34}{YOLOv3 runs significantly faster than other detection methods with comparable performance. Times from either an M40 or Titan X, they are basically the same GPU. \cite {DBLP:journals/corr/RedmonDGF15}}{figure.4.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.3.2}Person\_detector Package}{34}{subsubsection.4.2.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.11}{\ignorespaces ROS Topics and Messages in \texttt  {person\_detector} node}}{34}{figure.4.11}}
\newlabel{fig:pd}{{\relax 4.11}{34}{ROS Topics and Messages in \texttt {person\_detector} node}{figure.4.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.12}{\ignorespaces \textbf  {A detection demo scenario without thresholding detection confidence.} Before thresholding the confidence, some random detection appears in the detecion list.}}{35}{figure.4.12}}
\newlabel{fig:det_unfiltered}{{\relax 4.12}{35}{\textbf {A detection demo scenario without thresholding detection confidence.} Before thresholding the confidence, some random detection appears in the detecion list}{figure.4.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.13}{\ignorespaces A scene of both positive false and negative false case from the YOLO person detector}}{35}{figure.4.13}}
\newlabel{fig:wrong_det}{{\relax 4.13}{35}{A scene of both positive false and negative false case from the YOLO person detector}{figure.4.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.14}{\ignorespaces \textbf  {CvBrideg}: Convertion between ROS image messages and OpenCV images. \cite  {roscvbridge}}}{35}{figure.4.14}}
\newlabel{fig:cv_bridge}{{\relax 4.14}{35}{\textbf {CvBrideg}: Convertion between ROS image messages and OpenCV images. \cite {roscvbridge}}{figure.4.14}{}}
\citation{adam2006}
\citation{adam2006}
\citation{adam2006}
\citation{Felz2010}
\citation{adam2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Person Tracker}{36}{subsection.4.2.4}}
\newlabel{pipeline:PT}{{4.2.4}{36}{Person Tracker}{subsection.4.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4.1}Person Tracker Framework}{36}{subsubsection.4.2.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.15}{\ignorespaces Template patch $P_{T}$ and the corresponding image patch $P_{I;}(x,y)$ for a hypothesized position $(x, y)$. \cite  {adam2006}}}{37}{figure.4.15}}
\newlabel{fig:patch_matching}{{\relax 4.15}{37}{Template patch $P_{T}$ and the corresponding image patch $P_{I;}(x,y)$ for a hypothesized position $(x, y)$. \cite {adam2006}}{figure.4.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.4.2}Person\_tracker Package}{37}{subsubsection.4.2.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.16}{\ignorespaces ROS Topics and Messages in \texttt  {person\_tracker} node}}{37}{figure.4.16}}
\newlabel{fig:pt_node}{{\relax 4.16}{37}{ROS Topics and Messages in \texttt {person\_tracker} node}{figure.4.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.17}{\ignorespaces Demo scenario for person intersection}}{37}{figure.4.17}}
\newlabel{fig:person_intersec}{{\relax 4.17}{37}{Demo scenario for person intersection}{figure.4.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.18}{\ignorespaces Demo scenario for person bounding box lagging}}{38}{figure.4.18}}
\newlabel{fig:bbox_lag}{{\relax 4.18}{38}{Demo scenario for person bounding box lagging}{figure.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.19}{\ignorespaces Demo scenario for person intersection after modification}}{38}{figure.4.19}}
\newlabel{fig:person_intersec_mod}{{\relax 4.19}{38}{Demo scenario for person intersection after modification}{figure.4.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.20}{\ignorespaces Demo scenario for boundary check befores modification}}{38}{figure.4.20}}
\newlabel{fig:boundary_check}{{\relax 4.20}{38}{Demo scenario for boundary check befores modification}{figure.4.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.21}{\ignorespaces Demo scenario for boundary check after modification}}{38}{figure.4.21}}
\newlabel{fig:boundary_check_mod}{{\relax 4.21}{38}{Demo scenario for boundary check after modification}{figure.4.21}{}}
\citation{cao2017realtime}
\citation{DBLP:journals/corr/SimonJMS17}
\citation{journals/corr/WeiRKS16}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Feature Extractor}{39}{subsection.4.2.5}}
\newlabel{pipeline:FE}{{4.2.5}{39}{Feature Extractor}{subsection.4.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5.1}OpenPose Library}{39}{subsubsection.4.2.5.1}}
\newlabel{git:openpose}{{10}{39}{}{Hfootnote.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.22}{\ignorespaces A demo of \textit  {OpenPose\begingroup \let \@unexpandable@protect \xdef 14{\ref  {git:openpose}}\endgroup \unhbox \voidb@x \hbox {{\textsuperscript  {14}}}\relax }.}}{40}{figure.4.22}}
\newlabel{fig:openpose_demo}{{\relax 4.22}{40}{A demo of \textit {OpenPose\footref {git:openpose}}}{figure.4.22}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Befor intersection.}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {After intersection}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Modified: befor intersection}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Modified: after intersection}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Modified: befor intersection}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Modified: after intersection}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Before intersection with boundary}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {After intersection with boundary}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Modified: before intersection with boundary}}}{40}{figure.4.22}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Modified: after intersection with boundary}}}{40}{figure.4.22}}
\newlabel{subfig:coco_body_joints}{{\relax 4.23(a)}{40}{Subfigure 4 \relax 4.23(a)}{subfigure.\relax 4.23.1}{}}
\newlabel{sub@subfig:coco_body_joints}{{(a)}{40}{Subfigure 4 \relax 4.23(a)\relax }{subfigure.\relax 4.23.1}{}}
\newlabel{subfig:coco_body_map}{{\relax 4.23(b)}{40}{Subfigure 4 \relax 4.23(b)}{subfigure.\relax 4.23.2}{}}
\newlabel{sub@subfig:coco_body_map}{{(b)}{40}{Subfigure 4 \relax 4.23(b)\relax }{subfigure.\relax 4.23.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.23}{\ignorespaces COCO body model.}}{40}{figure.4.23}}
\newlabel{fig:coco_model}{{\relax 4.23}{40}{COCO body model}{figure.4.23}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {COCO body joints ordering.}}}{40}{figure.4.23}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {COCO body parts map}}}{40}{figure.4.23}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.24}{\ignorespaces An example of pose data output}}{40}{figure.4.24}}
\newlabel{fig:pose_data}{{\relax 4.24}{40}{An example of pose data output}{figure.4.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5.2}Openpose\_ros Package}{40}{subsubsection.4.2.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.25}{\ignorespaces ROS Topics and Messages of \texttt  {openpose\_ros} node}}{41}{figure.4.25}}
\newlabel{fig:openpose_ros}{{\relax 4.25}{41}{ROS Topics and Messages of \texttt {openpose\_ros} node}{figure.4.25}{}}
\citation{DBLP:journals/corr/ZhouH0XW17}
\citation{DBLP:conf/eccv/NewellYD16}
\citation{DBLP:conf/eccv/NewellYD16}
\citation{DBLP:conf/eccv/NewellYD16}
\citation{DBLP:journals/corr/ShahroudyLNW16}
\citation{DBLP:journals/corr/ShahroudyLNW16}
\citation{DBLP:journals/corr/ZhouH0XW17}
\citation{DBLP:journals/corr/ZhouH0XW17}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5.3}Stacked Hourglass Network}{42}{subsubsection.4.2.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.26}{\ignorespaces Stacked hourglass network for pose estimation consists of multiple stacked hourglass modules which allow for repeated bottom-up, top-down inference. \cite  {DBLP:conf/eccv/NewellYD16}}}{42}{figure.4.26}}
\newlabel{fig:stacked_hourglass_model}{{\relax 4.26}{42}{Stacked hourglass network for pose estimation consists of multiple stacked hourglass modules which allow for repeated bottom-up, top-down inference. \cite {DBLP:conf/eccv/NewellYD16}}{figure.4.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.5.4}Pose\_3d\_ros Package}{42}{subsubsection.4.2.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.27}{\ignorespaces ROS Topics and Messages of \texttt  {pose\_3d\_ros} node}}{42}{figure.4.27}}
\newlabel{fig:pose_3d_ros}{{\relax 4.27}{42}{ROS Topics and Messages of \texttt {pose\_3d\_ros} node}{figure.4.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.28}{\ignorespaces A visualization of the estimated 3D pose of a sitting subject from the NTU RGB+D dataset \cite  {DBLP:journals/corr/ShahroudyLNW16}. The image displayed is resized and zero-padded to a $256 \times 256$ patch. The 2D component of the original estimated pose $\mathaccentV {hat}05E{\mathbf  {P} _{2D}}$ is represented in the corresponding coordinate system of $[0, 256] \times [0, 256]$ and the depth value $\mathaccentV {hat}05E{\mathbf  {P}_{dep}}$ is estimated in corresponding scale. Therefore, $\mathaccentV {hat}05E{\mathbf  {P}_{3D}}$ is a \IeC {\textquotedblleft }pseudo\IeC {\textquotedblright } 3D skeletal representation in a \IeC {\textquotedblleft }3D image coordinate system\IeC {\textquotedblright }.}}{43}{figure.4.28}}
\newlabel{fig:3d_demo}{{\relax 4.28}{43}{A visualization of the estimated 3D pose of a sitting subject from the NTU RGB+D dataset \cite {DBLP:journals/corr/ShahroudyLNW16}. The image displayed is resized and zero-padded to a $256 \times 256$ patch. The 2D component of the original estimated pose $\hat {\mathbf {P} _{2D}}$ is represented in the corresponding coordinate system of $[0, 256] \times [0, 256]$ and the depth value $\hat {\mathbf {P}_{dep}}$ is estimated in corresponding scale. Therefore, $\hat {\mathbf {P}_{3D}}$ is a “pseudo” 3D skeletal representation in a “3D image coordinate system”}{figure.4.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.29}{\ignorespaces Configuration of 16 body joints in the 3D pose estimator proposed by \cite  {DBLP:journals/corr/ZhouH0XW17}. The labels of the 16 joints are: 1-right ankle, 2-right knee, 3-right hip, 4-left hip, 5-left knee, 6-left ankle, 7-spline base, 8-middle of spine, 9-neck, 10-head, 11-right hand, 12-right elbow, 13-right shoulder, 14-left shoulder, 15-left elbow, 16-left hand.}}{43}{figure.4.29}}
\newlabel{fig:3d_body_map}{{\relax 4.29}{43}{Configuration of 16 body joints in the 3D pose estimator proposed by \cite {DBLP:journals/corr/ZhouH0XW17}. The labels of the 16 joints are: 1-right ankle, 2-right knee, 3-right hip, 4-left hip, 5-left knee, 6-left ankle, 7-spline base, 8-middle of spine, 9-neck, 10-head, 11-right hand, 12-right elbow, 13-right shoulder, 14-left shoulder, 15-left elbow, 16-left hand}{figure.4.29}{}}
\citation{DBLP:journals/corr/LiuSXW16}
\citation{lin2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Data Manager}{44}{subsection.4.2.6}}
\newlabel{pipeline:DM}{{4.2.6}{44}{Data Manager}{subsection.4.2.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6.1}Formation of Pose Tensor}{44}{subsubsection.4.2.6.1}}
\citation{lin2018}
\citation{lin2018}
\citation{DBLP:journals/corr/Baradel0M17}
\citation{lin2018}
\citation{lin2018}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.30}{\ignorespaces (a) The body configuration of 15 joints (joint 8 is omitted). (b) The full body is unfolded into a tree structure, with joint 7 (\textit  {spine base}) as the root node (c) The topological ordering is defined by a cyclic path along the tree structure. Each limb is visited twice in the bidirectional traverse with repetition and each joint always appears with its neighbors in the sequence. The generated node sequence is 7-3-2-1-2-3-7-4-5-6-5- 4-7-9-10-9-13-12-11-12-13-9-14-15-16-15-14-9-7. \cite  {lin2018}}}{45}{figure.4.30}}
\newlabel{fig:pose_topo}{{\relax 4.30}{45}{(a) The body configuration of 15 joints (joint 8 is omitted). (b) The full body is unfolded into a tree structure, with joint 7 (\textit {spine base}) as the root node (c) The topological ordering is defined by a cyclic path along the tree structure. Each limb is visited twice in the bidirectional traverse with repetition and each joint always appears with its neighbors in the sequence. The generated node sequence is 7-3-2-1-2-3-7-4-5-6-5- 4-7-9-10-9-13-12-11-12-13-9-14-15-16-15-14-9-7. \cite {lin2018}}{figure.4.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.31}{\ignorespaces The 3D pose tensor $\mathbf  {T} \in \mathbf  {R}^{K \times 3L \times 3}$: the first dimension is the frame index, the second dimension is the $x$, $y$ and $z$ coordinates of all the body joints concatenated in the topological ordering designed in Figure \ref  {fig:pose_topo}, the third dimension contains raw coordinates, velocities, accelerations as the three channels. \cite  {lin2018}}}{46}{figure.4.31}}
\newlabel{fig:3_channel_struct}{{\relax 4.31}{46}{The 3D pose tensor $\mathbf {T} \in \mathbf {R}^{K \times 3L \times 3}$: the first dimension is the frame index, the second dimension is the $x$, $y$ and $z$ coordinates of all the body joints concatenated in the topological ordering designed in Figure \ref {fig:pose_topo}, the third dimension contains raw coordinates, velocities, accelerations as the three channels. \cite {lin2018}}{figure.4.31}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6.2}Pose Processing}{46}{subsubsection.4.2.6.2}}
\citation{usman2018}
\citation{Muller2010}
\citation{usman2018}
\citation{usman2018}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.32}{\ignorespaces An example of temporal P-Spline smoothing. Before smoothing (blue), the first 10 frames of the joint x position are: [123.908, 123.259, 0., 0., 0., 0., 0., 119.357 116.73, 121.292], After smoothing (green), the values are: [123.71374527 123.55038209, 122.86919667, 121.85577574, 120.69570604, 119.5745743, 118.67796725, 118.19147164, 118.47829254, 120.61210846]. The missing points in frame 2 to 6 have been smoothingly interpolated.}}{47}{figure.4.32}}
\newlabel{fig:pose_smoothing}{{\relax 4.32}{47}{An example of temporal P-Spline smoothing. Before smoothing (blue), the first 10 frames of the joint x position are: [123.908, 123.259, 0., 0., 0., 0., 0., 119.357 116.73, 121.292], After smoothing (green), the values are: [123.71374527 123.55038209, 122.86919667, 121.85577574, 120.69570604, 119.5745743, 118.67796725, 118.19147164, 118.47829254, 120.61210846]. The missing points in frame 2 to 6 have been smoothingly interpolated}{figure.4.32}{}}
\citation{usman2018}
\citation{usman2018}
\citation{usman2018}
\citation{usman2018}
\citation{usman2018}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.33}{\ignorespaces Statistical curve fitting model for relative relative joint positions of \textit  {Left Ankle} and \textit  {Left Hip} joints. (a) Polynomial Curve fitting model for estimation of $x$- coordinate of \textit  {Left Ankle} joint using \textit  {Left Hip} joint (b) Polynomial Curve fitting model for estimation of $y$-coordinate of \textit  {Left Ankle} joint using \textit  {Left Hip joint}. \cite  {usman2018}}}{48}{figure.4.33}}
\newlabel{fig:stat_model}{{\relax 4.33}{48}{Statistical curve fitting model for relative relative joint positions of \textit {Left Ankle} and \textit {Left Hip} joints. (a) Polynomial Curve fitting model for estimation of $x$- coordinate of \textit {Left Ankle} joint using \textit {Left Hip} joint (b) Polynomial Curve fitting model for estimation of $y$-coordinate of \textit {Left Ankle} joint using \textit {Left Hip joint}. \cite {usman2018}}{figure.4.33}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.34}{\ignorespaces Configuration of 5 body parts for spatial interpolation of missing joint positions \cite  {usman2018}}}{48}{figure.4.34}}
\newlabel{fig:body_model_config}{{\relax 4.34}{48}{Configuration of 5 body parts for spatial interpolation of missing joint positions \cite {usman2018}}{figure.4.34}{}}
\citation{usman2018}
\citation{usman2018}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.35}{\ignorespaces Complete body pose after temporal and spatial interpolation (a) Missing pose in some frames estimated by temporal interpolation (b) Occluded joint positions estimated by spatial interpolation (c) Missing joint positions in some frame estimated by temporal interpolation \cite  {usman2018}}}{49}{figure.4.35}}
\newlabel{fig:pose_smoothing_result}{{\relax 4.35}{49}{Complete body pose after temporal and spatial interpolation (a) Missing pose in some frames estimated by temporal interpolation (b) Occluded joint positions estimated by spatial interpolation (c) Missing joint positions in some frame estimated by temporal interpolation \cite {usman2018}}{figure.4.35}{}}
\newlabel{eqa:pose_norm}{{\relax 4.5}{49}{Pose Processing}{equation.4.2.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.36}{\ignorespaces Pose Normalization \cite  {usman2018}}}{50}{figure.4.36}}
\newlabel{fig:pose_norm}{{\relax 4.36}{50}{Pose Normalization \cite {usman2018}}{figure.4.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.37}{\ignorespaces ROS Topics and Messages in \texttt  {data\_manager\_2d} and \texttt  {data\_manager\_3d} nodes}}{50}{figure.4.37}}
\newlabel{fig:data_manager}{{\relax 4.37}{50}{ROS Topics and Messages in \texttt {data\_manager\_2d} and \texttt {data\_manager\_3d} nodes}{figure.4.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.6.3}Data\_manager Package}{50}{subsubsection.4.2.6.3}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 4.1}{\ignorespaces \textbf  {Data structure of Pose Pool}. Pose Pool is no more than a dictionary (Python) or map (C++). Person ID is used as the key, each time \texttt  {data\_manager\_3d} receives the person pose from \textit  {Pose Estimator}, it will first check if the person has already a record in the Pose Pool. If not, the Pose Pool will create a block for the person, otherweise Pose Pool will update the person's \texttt  {pose\_pool}. The \texttt  {pose\_pool} of each person is a concatenated array of pose data from different frames, and the pose data of each frame is an array of $(x, y, z)$ of all joints in the node sequence (e.g. in Figure \ref  {fig:pose_topo}). While another item member --- \texttt  {sample\_id} determines which frame should be handled. As default in our pipeline, we will process every single frame, so the \texttt  {sample\_id} list would be: [0, 1, 2 , 3, ...], at the end of the pose processing, the next sample id that should be handled will be generated and be appended to \texttt  {sample\_id} list. Once a person's \texttt  {pose\_pool} has achieved a predefined number K (here we set K = 10), we will generate the pose tensor from the K frames with pose processing as mentioned above. Then we store the pose tensor in the \texttt  {Person} message or gather all the persons in one \texttt  {FrameInfo} message and publish it. At last we remove the first frame in the person's \texttt  {pose\_pool}, and concatenate the coming pose frame to the end of it, so as to form a new pose tensor, while reserving previous $K-1$ pose frames.}}{51}{table.4.1}}
\newlabel{tab:pose_pool}{{\relax 4.1}{51}{\textbf {Data structure of Pose Pool}. Pose Pool is no more than a dictionary (Python) or map (C++). Person ID is used as the key, each time \texttt {data\_manager\_3d} receives the person pose from \textit {Pose Estimator}, it will first check if the person has already a record in the Pose Pool. If not, the Pose Pool will create a block for the person, otherweise Pose Pool will update the person's \texttt {pose\_pool}. The \texttt {pose\_pool} of each person is a concatenated array of pose data from different frames, and the pose data of each frame is an array of $(x, y, z)$ of all joints in the node sequence (e.g. in Figure \ref {fig:pose_topo}). While another item member --- \texttt {sample\_id} determines which frame should be handled. As default in our pipeline, we will process every single frame, so the \texttt {sample\_id} list would be: [0, 1, 2 , 3, ...], at the end of the pose processing, the next sample id that should be handled will be generated and be appended to \texttt {sample\_id} list. Once a person's \texttt {pose\_pool} has achieved a predefined number K (here we set K = 10), we will generate the pose tensor from the K frames with pose processing as mentioned above. Then we store the pose tensor in the \texttt {Person} message or gather all the persons in one \texttt {FrameInfo} message and publish it. At last we remove the first frame in the person's \texttt {pose\_pool}, and concatenate the coming pose frame to the end of it, so as to form a new pose tensor, while reserving previous $K-1$ pose frames}{table.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.7}Action Predictor}{51}{subsection.4.2.7}}
\newlabel{pipeline:AP}{{4.2.7}{51}{Action Predictor}{subsection.4.2.7}{}}
\citation{usman2018}
\citation{usman2018}
\citation{usman2018}
\citation{lin2018}
\citation{lin2018}
\citation{lin2018}
\citation{DBLP:journals/corr/XiongZWLT17}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7.1}Network Structure}{52}{subsubsection.4.2.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.38}{\ignorespaces Architecture of Pose ConvNet \cite  {usman2018}}}{52}{figure.4.38}}
\newlabel{fig:posenet_2d}{{\relax 4.38}{52}{Architecture of Pose ConvNet \cite {usman2018}}{figure.4.38}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.39}{\ignorespaces \textbf  {Architecture of PoseNet}. A CNN of two Conv layers, two Max Pooling layers and two FC layers. Hyperparameters such as number of kernels in Conv layers and size of FC layers are determined according the scale of the dataset. \cite  {lin2018}}}{52}{figure.4.39}}
\newlabel{fig:posenet_3d}{{\relax 4.39}{52}{\textbf {Architecture of PoseNet}. A CNN of two Conv layers, two Max Pooling layers and two FC layers. Hyperparameters such as number of kernels in Conv layers and size of FC layers are determined according the scale of the dataset. \cite {lin2018}}{figure.4.39}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7.2}Action Proposal}{52}{subsubsection.4.2.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.40}{\ignorespaces Action Classification with and without Proposal. The top diagram displays the action score of the action standing (green) and walking (red) along the timeline (frames) respectively. The bottom diagram shows the action label (action with higher scores, 0 -- standing, 1 -- walking) of each frame, the green one stands for the prediction based on the current pose tensor, while the red one stands for the proposed label.}}{53}{figure.4.40}}
\newlabel{fig:action_proposal_s1}{{\relax 4.40}{53}{Action Classification with and without Proposal. The top diagram displays the action score of the action standing (green) and walking (red) along the timeline (frames) respectively. The bottom diagram shows the action label (action with higher scores, 0 -- standing, 1 -- walking) of each frame, the green one stands for the prediction based on the current pose tensor, while the red one stands for the proposed label}{figure.4.40}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.7.3}Pose\_net Package}{53}{subsubsection.4.2.7.3}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Action Grouping Algorithm}}{54}{algocf.1}}
\newlabel{alg:pose_proposal}{{1}{54}{Action Proposal}{algocf.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.41}{\ignorespaces ROS Topics and Messages in \texttt  {pose\_net\_2d} and \texttt  {pose\_net\_3d} node}}{55}{figure.4.41}}
\newlabel{fig:pose_net}{{\relax 4.41}{55}{ROS Topics and Messages in \texttt {pose\_net\_2d} and \texttt {pose\_net\_3d} node}{figure.4.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.8}Visual Agency}{55}{subsection.4.2.8}}
\newlabel{pipeline:VA}{{4.2.8}{55}{Visual Agency}{subsection.4.2.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.8.1}Visual\_agency Package}{55}{subsubsection.4.2.8.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 4.42}{\ignorespaces ROS Topics and Messages in \texttt  {visual\_agency} node}}{56}{figure.4.42}}
\newlabel{fig:visual_agency}{{\relax 4.42}{56}{ROS Topics and Messages in \texttt {visual\_agency} node}{figure.4.42}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.9}Pipeline Utilities}{57}{subsection.4.2.9}}
\@setckpt{Main/4_Pipeline_Design}{
\setcounter{page}{58}
\setcounter{equation}{9}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{20}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{2}
\setcounter{subsection}{9}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{42}
\setcounter{table}{1}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{41}
\setcounter{bookmark@seq@number}{42}
\setcounter{blindtext}{1}
\setcounter{Blindtext}{5}
\setcounter{blind@countparstart}{0}
\setcounter{blindlist}{0}
\setcounter{blindlistlevel}{0}
\setcounter{blindlist@level}{0}
\setcounter{blind@listcount}{0}
\setcounter{blind@levelcount}{0}
\setcounter{blind@randomcount}{0}
\setcounter{blind@randommax}{1}
\setcounter{blind@pangramcount}{0}
\setcounter{blind@pangrammax}{1}
\setcounter{Changes@AuthorCount}{1}
\setcounter{Changes@Author}{0}
\setcounter{Changes@AddCount}{0}
\setcounter{Changes@DeleteCount}{0}
\setcounter{Changes@ReplaceCount}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{1}
\setcounter{algocfproc}{1}
\setcounter{algocf}{1}
\setcounter{float@type}{8}
\setcounter{lstnumber}{1}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
