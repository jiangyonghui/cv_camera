% !TeX root = ../thesis.tex

\chapter{Introduction}
\label{sec:introduction}

In this chapter, we first introduce context of the research on human action detection and recognition as well as real-time application based on Robot Operating System. Then the motivation, contribution and limitations of our development are explained. At last, the organization of this thesis is described. 

\section{Presupposed Knowledge}
\subsection{Action Detection and Recognition}

Human action detection and recognition has attracted an increasing amount of attention in recent years.
The task of human action detection and recognition is to automatically analyze the ongoing activity in a given video and correctly classify the video into an action category. A video is an arbitrarily-lengthed sequence consisting of 2D image frames. In a more general case of action detection, the temporal localization is implemented to predict the starting and ending times of all occurring actions in a continuous video of a long period. In this thesis, we firstly focus on action recognition of well-trimmed videos or clips in which the first and the last frame roughly correspond to the beginning and end of an action, then we will also test and evaluate the pipeline on untrimmed raw videos. 

Human action recognition has become an indispensable part in numerous domains and applications of computer vision. One of the most widely applied scenarios is video surveillance, which is crucial for public security, like in airports, train stations, shopping malls, banks, etc. A scene of video surveillance in an airport lobby in three distinct camera viewpoints from XX is illustrated in Figure XX. Security violations such as physical conflicts or vandalism in public places or abnormalities
in the perimeter of a private house need to be detected and reported the first time by a competent action detection and recognition system. Apart from the consideration of security, behavior analysis of customers is essential for business management. As is shown in Figure XX, [EDEAK] ...  According to IHS Markit\footnote{\url{https://ihsmarkit.com/research-analysis}}, in 2017, 98 million surveillance cameras and 29 million HD CCTV surveillance cameras were installed across the world. By the end of 2016, the total number of installed cameras in Germany has reached 5.2 million\footnote{\url{https://technology.ihs.com/583518}} and by 2020, China will be expected to build a network of 626 million surveillance cameras. With the rapid development of the surveillance industry, the demands on advanced action recognition are drastically increased. Another critical application is the recognition of user gestures and pedestrian behavior in human machine interaction and autonomous driving. [some examples here...]

However, understanding what a human is doing in a video sequence is never a trivial task for computers. Unlike some object detection and recognition tasks in 2D images, human action recognition remains a rather challenging problem due to several factors such as variations of view-points and appearances, complex motion styles, large intra-class diversity and distraction of background clutters.
\medskip

\subsection{ROS - Robot Operating System}

In recent years the Robot Operating System (ROS) \cite{quigley2009ros} has become the ‘de facto’ standard framework for robotics software development. The Robot Operating System is an open-source, meta-operating system that provides services usually expected from an operating system, including hardware abstraction, low-level device control, message-passing between processes, package management, tools and libraries useful for typical robotics applications, such as navigation, motion planning, image and 3D data processing. In the context of this thesis, the following features of ROS are taken into consideration. The first one is, ROS ‘per se’ is designed to be as distributed and modular as possible, thus providing high flexibility of modularity, reusage and substitution of its packages. This feature serves as the foundation of the pipeline, which is composed of several interactive modules (implemented as ROS packages and nodes), including video streams input, person detection and tracking, person pose estimation, data preprocessing, action prediction as well as data postprocessing. As is shown in Figure \ref{fig:ros_pub_and_sub_intro}, through a topic/message communication mechanism, ROS nodes can set up publishers and subscribers to exchange information to fulfill its own part of functionality. 

\begin{wrapfigure}{r}{0.5\textwidth}
  \begin{center}
    \includegraphics[width=0.5\textwidth]{Introduction/ros_pub_and_sub.png}
  \end{center}
  \caption{ROS Publisher and Subscriber}
  \label{fig:ros_pub_and_sub_intro}
\end{wrapfigure}

Secondly, ROS provides graphic presentation of information flow from the nodes and topics via some built-in tools, e.g. rqt plugins\footnote{\url{http://wiki.ros.org/rqt/Plugins}}, ros command line \footnote{\url{http://wiki.ros.org/ROS/CommandLineTools}}. This feature enables a clear navigation through the whole pipeline and is straight-forward for debugging and logging. 

From the perspective of implementation, ROS has integrated a collection of software tools and libraries into the framework. As the two main client libraries, roscpp\footnote{\url{http://wiki.ros.org/roscpp}} offers the C++ APIs for high performance libraries and rospy\footnote{\url{http://wiki.ros.org/rospy}}(Python) could be utilized for quick prototype and testing with ROS. More details of ROS will be covered in Section \ref{subsec:ros} and the design of pipeline modules will be discussed in Section \ref{sec:pipeline_design}.


\section{Motivation}
\blindtext

\section{Goal Description and Limitations}
\blindtext

\paragraph{Contribution}
\blindtext

\paragraph{Limitations}
\blindtext

\section{Outline}
\blindtext


